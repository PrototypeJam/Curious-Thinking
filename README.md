# Extended Mind Diagrams

_______________________________

# 1) Intro + Quick-Start (fast path, zero wheel-reinvention)

## Intro — what this gives you and why

You already have a working HBR-style quadrant system (Jason’s repo) that can add overlays and gradients quickly using AI-generated Matplotlib code. Your goal now is to **generalize** that capability so you can:

* produce a clean diagram in minutes,
* iterate via small “delta prompts,” and
* scale up to **config- and data-driven** ensembles when you want portfolio views or “what-if” sweeps.

You’ll keep three production modalities in one toolkit:

* **Prompt-only** for fastest ideation,
* **Config dict** for repeatable one-offs,
* **CSV/JSON** for ensembles/variants generated by a model.

This quick-start gets you from clone → first image → parameterized reuse in one sitting.

## Quick-Start — duplicate current setup, then generalize

### A. Reproduce the repo outputs (fastest)

1. Clone and open the notebook

* `git clone https://github.com/Smuckwell-Industries/Curious-Thinking.git`
* Open `hunter-scout-gardener-farmer/hunter_scout_gardener_farmer.ipynb` in Jupyter or VS Code.
* `pip install matplotlib numpy` if needed.

2. Run cells to generate the base quadrants and overlays

* Confirm an `images/` folder exists; if not, create it.
* Execute the plotting cells; you should see the quadrant figures and any overlay/gradient variant.

3. Save your “baseline” image

* Export to PNG (300 DPI) and SVG.

That reproduces the current behavior exactly and keeps you engaged with immediate wins.

### B. Turn the notebook into your reusable engine (15–20 min)

1. Extract a **style module**

* Create `my_viz_style.py` (use the stub in your doc) and import it at the top of the notebook.
* Apply the style once; keep typography and palette out of plotting code.

2. Parameter block

* Add a `CONFIG` dict at the top (title, axes labels, quadrant text).
* Replace hard-coded labels/positions with `CONFIG` references.

3. Add **delta prompts** to your chat workflow

* Keep everything else the same; change one thing at a time (font size, label offset, alpha).
* Iterate 2–4 times, then export.

### C. Enable the data-driven mode (only when you want ensembles)

1. Create `configs/<topic>/axes.json`, `overlays.json`, `examples.csv`, and a `config.json` that points to those files (use your schemas).
2. Drop in the minimal `render_quadrant.py` runner.
3. Render once:

* `python render_quadrant.py configs/<topic>/config.json`

4. For portfolios: loop over multiple scenario folders (five variants in one go).

Result: you can go from blank repo to reproduced figure to generalized, reusable system in under an hour, and you have a path to batch scenarios when you’re ready.

---

# Comprehensive AI-Assisted Visualization Capability Framework

---

## Part 1: Mental Models and Conceptual Foundation

### Pattern Priority Guide (Start Here)

**Master these patterns first** — highest signal-to-time ratio for executive, legal, and AI strategy work:

1. **Quadrant/Matrix with overlays** — fastest route from concept to executive insight
2. **Layered models** (stacked or nested) — ideal for governance, responsibilities, capability layers
3. **Annotated flow/timeline** — best for "how work gets done" and regulatory/launch roadmaps

**Use selectively** when the story specifically demands them:

- **Bubble overlays on quadrants** — adds cost/scale dimension without clutter
- **Heatmap matrices** — for coverage/comparison across categories (e.g., telemetry × system layers)
- **Sankey/force-directed** — high cognitive load; justify with discovery or allocation narrative

### Conceptual Mapping Diagnostics

Before prompting, answer these questions to determine the right visualization structure:

**Q1: What's the core relationship I'm trying to show?**
- Comparison/contrast → Quadrant or matrix
- Process/sequence → Flow or timeline
- Hierarchy/containment → Nested circles or layers
- Distribution/clustering → Scatter or bubble
- Composition → Sankey or stacked area
- Network/connections → Force-directed graph

**Q2: How many dimensions?**
- 2 dimensions → Simple quadrant
- 3 dimensions → Quadrant + color/size
- 4+ dimensions → Multiple panels or interactive
- Continuous vs categorical → Determines axis type

**Q3: What's the audience mental model?**
- Academic → Citations, precise definitions
- Executive → Clear insights, minimal detail
- Technical → Accuracy, reproducibility
- General → Metaphors, familiar examples

**Q4: What action should this enable?**
- Classification → "Where does X fit?"
- Comparison → "Which is better for Y scenario?"
- Discovery → "What patterns exist?"
- Decision → "What should we do?"

---

## Part 2: Cognitive Scaffolding Process

### Before You Prompt Anything

**Step 1: CONCEPT AUDIT**
- What's the core insight I want to communicate?
- What are the 2-4 key dimensions/variables?
- What examples or data points exist?
- What metaphors might resonate?

**Step 2: AUDIENCE MAPPING**
- Who will see this?
- What do they already understand?
- What misconceptions might they have?
- What decision does this enable?

**Step 3: VISUAL HYPOTHESIS**
- Sketch on paper (literally — 2 minutes)
- What shape feels right? (quadrant/flow/matrix/etc)
- Where should emphasis be? (size/color/position)
- What should be labeled vs implied?

**Step 4: PROMPT CONSTRUCTION**
- Start with structure: "[Type] diagram with [axes/elements]"
- Add content: "Include [specific examples/labels]"
- Specify style: "Use [aesthetic] with [constraints]"
- Define output: "Export as [format] at [resolution]"

**Step 5: ITERATION PROTOCOL**
- Generate → Evaluate → Identify ONE thing to change
- Use delta prompts (see below)
- Repeat 3-5 times maximum
- Save final version with descriptive name

### Delta Prompts for Fast Iteration

Most time is lost rewriting whole prompts. Delta prompts target one change:

```
Keep everything else the same. Only:
1. Move the 'Agents' label 30px down and 40px right
2. Reduce quadrant alpha by 0.15
3. Export both PNG and SVG
```

This keeps the model anchored to prior state and accelerates convergence.

---

## Part 3: Three Production Modalities

### When to Use Each Approach

**Prompt-only** → Fastest ideation, exploring concepts
**Config-dict** → Repeatable single artifact, team sharing
**CSV/JSON data-driven** → Ensemble/portfolio analysis, multi-scenario iteration, client data merges

### Modality 1: Prompt-Only (Fastest Iteration)

**Initial prompt template:**
```
Create an HBR-style 2x2 quadrant diagram using matplotlib.

Topic: [YOUR TOPIC]
X-axis: [LEFT LABEL] → [RIGHT LABEL]
Y-axis: [BOTTOM LABEL] → [TOP LABEL]

Quadrants:
- Lower-left: [NAME] - [DESCRIPTION]
- Upper-left: [NAME] - [DESCRIPTION]
- Lower-right: [NAME] - [DESCRIPTION]
- Upper-right: [NAME] - [DESCRIPTION]

Style: Clean professional appearance, sans-serif fonts, muted color palette, 
300 DPI output. Make all parameters easy to modify.

Generate complete runnable Python code with clear comments.
```

**Refinement using delta prompts:**
```
[After first generation]
Keep everything else the same. Only adjust title to 16pt bold blue (#084B8A).

[After second generation]
Keep everything else the same. Only add a subtitle: "Mapping X across Y dimensions"
positioned 0.94 on the figure.

[After third generation]  
Keep everything else the same. Only add gradient overlay for "High Risk" region 
centered at (1.2, 1.2) with Gaussian falloff.
```

### Modality 2: Config-Dict (Reusable Templates)

**Create base template:**

```python
# saved as: ~/viz_templates/quadrant_base.py

"""
Standard quadrant diagram template
Usage: Modify CONFIG dict, run script
"""

CONFIG = {
    'topic': 'Your Topic Here',
    'title': 'Main Title',
    'subtitle': 'Optional subtitle',
    
    'x_axis': {
        'left': 'Left Label',
        'right': 'Right Label',
        'label': 'X-Axis Concept'
    },
    
    'y_axis': {
        'bottom': 'Bottom Label',
        'top': 'Top Label',
        'label': 'Y-Axis Concept'
    },
    
    'quadrants': {
        'lower_left': {
            'name': 'Quadrant 1',
            'description': 'Description here',
            'examples': ['Example 1', 'Example 2']
        },
        'upper_left': {
            'name': 'Quadrant 2',
            'description': 'Description here',
            'examples': ['Example 1', 'Example 2']
        },
        'lower_right': {
            'name': 'Quadrant 3',
            'description': 'Description here',
            'examples': ['Example 1', 'Example 2']
        },
        'upper_right': {
            'name': 'Quadrant 4',
            'description': 'Description here',
            'examples': ['Example 1', 'Example 2']
        }
    },
    
    'style': {
        'colors': ['#e6f2e6', '#e6f0f7', '#f2f2e6', '#f7e6e6'],
        'font': 'Arial',
        'figure_size': (10, 10),
        'dpi': 300
    }
}

# Then prompt: "Generate matplotlib code that uses this CONFIG dict"
```

### Modality 3: Data-Driven (Ensemble Analysis)

**Why this matters:** When you move to second-level analysis, you'll use a model to rapidly generate structured scenario data (variants, overlays, example points) and re-render families of diagrams. This enables portfolio reviews and "what-if" sweeps.

#### Minimal Schemas

**1. axes.json** — Axis configuration
```json
{
  "x_axis": {
    "left": "Low Autonomy",
    "right": "High Autonomy",
    "label": "Level of Autonomy",
    "limits": [-2.5, 2.5],
    "ticks": [-2, -1, 0, 1, 2]
  },
  "y_axis": {
    "bottom": "Narrow Scope",
    "top": "Broad Scope",
    "label": "Authority Scope",
    "limits": [-2.5, 2.5],
    "ticks": [-2, -1, 0, 1, 2]
  }
}
```

**2. overlays.json** — Named regions with rendering parameters
```json
{
  "overlays": [
    {
      "name": "High Risk Zone",
      "type": "gaussian",
      "center": [1.2, 1.2],
      "spread": [1.8, 1.8],
      "color": "#2E86C1",
      "alpha": 0.5,
      "label_position": [1.2, 1.7]
    },
    {
      "name": "Comfort Zone",
      "type": "polygon",
      "coordinates": [[-2, -2], [0, -2], [0, 0], [-2, 0]],
      "edge_color": "#2E8B57",
      "line_style": "--",
      "line_width": 2.5,
      "label_position": [-1, -1]
    }
  ]
}
```

**3. examples.csv** — Data points to plot
```csv
x,y,label,group,size,color
-1.5,-1.5,"Traditional Assistant","legacy",100,#084B8A
1.2,1.5,"Autonomous Agent","emerging",200,#2E86C1
0.0,0.0,"Hybrid System","current",150,#2E8B57
```

**4. config.json** — Top-level configuration
```json
{
  "title": "AI Autonomy Landscape",
  "subtitle": "Mapping Current and Emerging Capabilities",
  "axes_file": "configs/autonomy/axes.json",
  "overlays_file": "configs/autonomy/overlays.json",
  "examples_file": "configs/autonomy/examples.csv",
  "output": {
    "png": "images/autonomy_landscape.png",
    "svg": "images/autonomy_landscape.svg"
  },
  "style": {
    "dpi": 300,
    "font": "Arial",
    "colors": ["#e6f2e6", "#e6f0f7", "#f2f2e6", "#f7e6e6"]
  }
}
```

#### Graceful Fallbacks

Rendering code should:
- If a file is missing, render without that layer and log a one-line warning
- If a field is unknown, ignore it; do not crash
- Allow partial configurations (e.g., axes only, no overlays)

**Prompt for implementing this:**
```
Modify the quadrant rendering code to optionally load configuration from JSON files:
- axes.json for axis labels and limits
- overlays.json for named regions (polygon or gaussian types)
- examples.csv for data points to plot

If any file is missing, log a warning and render without that layer.
If any field is unknown, ignore it gracefully.
Include error handling and informative messages.
```

#### Worked Example: Three Ways to Produce the Same Figure

**Directory structure:**
```
viz_project/
├── render_quadrant.py          # Renderer script
├── my_viz_style.py             # Style module
├── configs/
│   └── autonomy/
│       ├── config.json
│       ├── axes.json
│       ├── overlays.json
│       └── examples.csv
└── images/                     # Output directory
```

**Way 1: Pure prompt** (5-10 minutes)
```
Create a 2x2 quadrant showing AI autonomy (x-axis) vs authority scope (y-axis).
Include examples: Traditional Assistant (-1.5,-1.5), Autonomous Agent (1.2,1.5),
Hybrid System (0,0). Add a "High Risk Zone" gradient overlay in upper right.
```

**Way 2: Config dict** (2-3 minutes if template exists)
```python
# autonomy_map.py
from quadrant_base import render_figure
from my_viz_style import apply_style, export

CONFIG = {
    'title': 'AI Autonomy Landscape',
    'x_axis': {'left': 'Low Autonomy', 'right': 'High Autonomy'},
    'y_axis': {'bottom': 'Narrow Scope', 'top': 'Broad Scope'},
    # ... rest of config
}

apply_style()
fig = render_figure(CONFIG)
export(fig, 'images/autonomy.png', 'images/autonomy.svg')
```

**Way 3: Data-driven** (30 seconds if files exist)
```bash
python render_quadrant.py configs/autonomy/config.json
```

#### Generating Config Files with AI

**Prompt for creating ensemble scenarios:**
```
I need to explore 5 different scenarios for AI governance models.

For each scenario, generate:
- axes.json with different axis labels reflecting that scenario's focus
- overlays.json with 2-3 named regions appropriate to that scenario
- examples.csv with 6-8 representative systems/approaches

Output as a directory structure with scenario names: 
scenarios/regulatory_heavy/, scenarios/market_driven/, etc.

Make each scenario internally consistent and distinct from the others.
```

This enables rapid "what-if" exploration: generate 10 scenarios, render all 10, review as a portfolio.

---

## Part 4: Style Module and Automation

### Style Module Stub

```python
# my_viz_style.py
"""
Personal visualization style system
Vendor-neutral, reusable across projects
"""

from matplotlib import pyplot as plt
from matplotlib import rcParams

# Color palette
PALETTE = {
    "ink": "#222222",           # Primary text
    "muted": "#6B7280",         # Secondary text
    "accent": "#0F6CBD",        # Highlights
    "q1": "#E6F0F7",            # Quadrant 1
    "q2": "#E6F2E6",            # Quadrant 2
    "q3": "#F7E6E6",            # Quadrant 3
    "q4": "#F2F2E6",            # Quadrant 4
}

# Standard figure sizes
SIZES = {
    "square_small": (7.5, 7.5),
    "square_medium": (10, 10),
    "square_large": (12, 12),
    "wide": (12, 8),
    "tall": (8, 12)
}

def apply_style():
    """Apply standard style settings"""
    rcParams.update({
        "figure.dpi": 300,
        "font.family": "sans-serif",
        "font.sans-serif": ["Arial", "Helvetica", "DejaVu Sans"],
        "axes.edgecolor": PALETTE["muted"],
        "axes.labelcolor": PALETTE["ink"],
        "axes.labelsize": 11,
        "axes.titlesize": 14,
        "xtick.labelsize": 10,
        "ytick.labelsize": 10,
    })

def export(fig, path_png, path_svg=None):
    """Export figure with consistent settings"""
    fig.savefig(path_png, bbox_inches="tight", facecolor='white', dpi=300)
    if path_svg:
        fig.savefig(path_svg, bbox_inches="tight", facecolor='white')
    print(f"Exported: {path_png}")
    if path_svg:
        print(f"Exported: {path_svg}")
```

### Minimal Batch Renderer

```python
# render_quadrant.py
"""
Simple batch renderer for JSON configs
Usage: python render_quadrant.py configs/my_diagram.json
"""

import json
import sys
from pathlib import Path
from my_viz_style import apply_style, export
from quadrant_base import render_figure

def load_config(config_path):
    """Load and validate configuration"""
    with open(config_path) as f:
        config = json.load(f)
    
    # Load referenced files with graceful fallbacks
    if 'axes_file' in config:
        try:
            with open(config['axes_file']) as f:
                config['axes'] = json.load(f)
        except FileNotFoundError:
            print(f"Warning: {config['axes_file']} not found, using defaults")
    
    if 'overlays_file' in config:
        try:
            with open(config['overlays_file']) as f:
                config['overlays'] = json.load(f)
        except FileNotFoundError:
            print(f"Warning: {config['overlays_file']} not found, skipping overlays")
    
    if 'examples_file' in config:
        try:
            import pandas as pd
            config['examples'] = pd.read_csv(config['examples_file'])
        except FileNotFoundError:
            print(f"Warning: {config['examples_file']} not found, skipping examples")
    
    return config

def main():
    if len(sys.argv) < 2:
        print("Usage: python render_quadrant.py <config.json>")
        sys.exit(1)
    
    config_path = sys.argv[1]
    config = load_config(config_path)
    
    apply_style()
    fig = render_figure(config)
    
    out_png = config.get('output', {}).get('png', 'output.png')
    out_svg = config.get('output', {}).get('svg', None)
    
    Path(out_png).parent.mkdir(parents=True, exist_ok=True)
    export(fig, out_png, out_svg)

if __name__ == "__main__":
    main()
```

---

## Part 5: Quality Assurance

### CRISP — 30-Second Pre-Export Quality Bar

Before exporting any diagram, check:

- **Contrast:** Will this screenshot be legible in grayscale printouts?
- **Readability:** Is every label ≥10–11pt and non-overlapping?
- **Information density:** Did I remove any element that isn't essential to the insight?
- **Story:** Can someone unfamiliar with the topic state the main insight in one sentence after 30 seconds?
- **Printability:** 300 DPI PNG and SVG saved with margins; dark/light variants if needed?

### Effectiveness Checklist

Does this figure meet all five criteria? If no, which need work?

- [ ] **Clarity** — A first-time viewer can state the main message in one sentence
- [ ] **Actionability** — The figure supports a choice or reveals a trade-off
- [ ] **Fidelity** — Labels/examples accurately represent the underlying idea or data
- [ ] **Brevity** — No element that doesn't earn its place
- [ ] **Transferability** — Style and structure can be reused for a related concept

### Accessibility & Brand Safety

Non-negotiable requirements for client deliverables:

- Use colorblind-safe palettes (Okabe–Ito, ColorBrewer)
- Ensure minimum 4.5:1 contrast for text against backgrounds
- Prefer system fonts available on client devices (Arial, Helvetica, Inter)
- If adopting client branding, map your palette and type scale to their guidelines once, then codify in `my_viz_style.py`

### Governance & IP Hygiene

For legal/consulting contexts:

- Record model, version, and date for AI-generated code or figures
- Store prompt/response transcripts that materially shaped the artifact
- Use permissive licenses for template code you plan to share (MIT)
- Confirm client brand usage rights before distributing public versions

---

## Part 6: Atomic Prompt Building Blocks

Assemble prompts faster using these modular components:

**Structure:**
```
Create a [quadrant|matrix|flow|timeline|layered] diagram; x = [..], y = [..]
```

**Style:**
```
HBR-style; sans-serif fonts; muted palette; remove chartjunk; 300 DPI output
```

**Overlays:**
```
Add semi-transparent regions named [..] with dashed borders at coordinates [..]
```

**Gradients:**
```
Gaussian intensity centered at (x,y); contour levels at [0.3, 0.6, 0.9]; clip to bounds
```

**Labels:**
```
Set title "[..]", subtitle "[..]"; use 16pt/12pt; align left
```

**Export:**
```
Save PNG and SVG to ./images/; add 5% margins; generate light and dark mode versions
```

**Delta iteration:**
```
Keep everything else the same. Only: [1] move X label to [coords], [2] change Y color to [hex], [3] add Z annotation
```

---

## Part 7: Skill Progression Path

### Week 1: Mastery of Basics

**Objectives:**
- Produce 5 quadrants on distinct topics; each ≤3 iterations to final
- Add overlays to 2 of them; demonstrate one gradient version
- **Outcome metric:** Time-to-first-useful-figure ≤10 minutes by Day 5

**Daily practice:**
- Day 1-2: Generate simple quadrants using prompt-only approach
- Day 3-4: Add overlays and refine positioning
- Day 5: Create gradient version and optimize workflow

### Week 2: Style Consistency

**Objectives:**
- Create `my_viz_style.py` with fonts, palette, margins, export helpers
- Re-render Week 1 figures using the style module; visual consistency ≥90%
- **Outcome metric:** Style refactor time per figure ≤3 minutes

**Daily practice:**
- Day 1: Build style module from examples
- Day 2-3: Refactor all Week 1 diagrams
- Day 4-5: Create 3 new diagrams using style module from start

### Week 3: Advanced Patterns

**Objectives:**
- Build one layered model, one annotated flow, one matrix heatmap
- **Outcome metric:** Get feedback from 3 peers; iterate if 2+ identify confusion

**Daily practice:**
- Day 1-2: Layered model for governance/capability structure
- Day 3-4: Flow diagram for process/timeline
- Day 5: Matrix heatmap for comparison across categories

### Week 4: Integration and Data-Driven

**Objectives:**
- Ship 3 diagrams into live work artifacts (deck, memo, client brief)
- Create first data-driven ensemble (5+ variants from JSON configs)
- **Outcome metric:** Each diagram used to support a decision in a meeting

**Daily practice:**
- Day 1-2: Integrate diagrams into real deliverables
- Day 3-4: Build config-based templates and JSON schemas
- Day 5: Generate ensemble scenarios and batch render

---

## Part 8: Error Patterns and Fixes

| Mistake | Why It Happens | Fix |
|---------|----------------|-----|
| Overcrowded labels | Too much text in limited space | Use abbreviations + legend; reduce font size incrementally |
| Poor contrast | Default colors don't separate | Test in grayscale mode; use color-safe palettes |
| Misaligned elements | Manual positioning fragile | Use relative coordinates; parameterize positions |
| Inconsistent sizing | Each diagram styled differently | Always import and apply style module |
| Lost in iteration | Too many versions, can't track | Name files: `topic_v1_basic.png`, `topic_v2_overlays.png` |
| Overlapping text | Auto-placement collision | Manually adjust or use matplotlib's `adjustText` library |
| Large file sizes | Excessive DPI or detail | 300 DPI for print, 150 for screen; simplify unnecessary elements |

---

## Part 9: Complete Workflow Examples

### Example 1: Autonomous Entities Framework

**Context:** You want to map different types of autonomous systems across capability and autonomy dimensions.

**Step 1: Concept Audit (2 min)**
- Core insight: Autonomy and capability are independent dimensions
- Dimensions: Level of autonomy (x), Scope of capabilities (y)
- Examples: Copilot, autonomous vehicles, AI advisors, robotic assembly
- Metaphor: "From assistants to agents"

**Step 2: Visual Hypothesis (2 min)**
- Sketch: 2x2 quadrant feels right
- Emphasis: Upper-right "Agents" quadrant is highest risk
- Labels: Clear examples in each quadrant

**Step 3: Initial Prompt (10 min)**
```
Create an HBR-style 2x2 quadrant diagram for "Autonomous Entity Capabilities"

X-axis: Level of Autonomy (left: Human-in-Loop → right: Fully Autonomous)
Y-axis: Scope of Authority (bottom: Narrow/Task-Specific → top: Broad/Strategic)

Quadrants:
- Lower-left: "Assistants" - Human-supervised, narrow tasks
  Examples: GitHub Copilot, Grammarly, Calculator apps
- Upper-left: "Advisors" - Human-supervised, strategic input  
  Examples: Strategic planning AI, Research assistants
- Lower-right: "Executors" - Autonomous, narrow tasks
  Examples: Automated trading bots, Robotic assembly
- Upper-right: "Agents" - Autonomous, strategic decisions
  Examples: Autonomous vehicles, Experimental AI CEOs

Style: Clean professional, sans-serif, muted colors, 300 DPI. 
Make parameters easy to modify.
```

**Step 4: Refinement with Delta Prompts (10 min)**
```
[After initial generation]
Keep everything else the same. Only add gradient overlay showing "Risk Level" 
increasing toward upper-right quadrant, centered at (1.2, 1.2).

[After second iteration]
Keep everything else the same. Only add subtitle "Mapping AI System Independence 
and Impact" positioned at y=0.94.

[After third iteration]
Keep everything else the same. Only increase example font size to 10pt and 
add slight transparency to quadrant backgrounds (alpha=0.7).
```

**Step 5: Export (2 min)**
```
Export as PNG (300 DPI) and SVG to ./images/autonomous_entities.{png,svg}
```

**Total time: ~26 minutes from concept to final**

### Example 2: LLM Evaluation Framework (Data-Driven)

**Context:** You want to explore different evaluation approaches across capability and data requirements, then generate 5 scenario variants.

**Step 1: Create Base Schemas (15 min)**

Create `configs/llm_eval/axes.json`:
```json
{
  "x_axis": {
    "left": "Simple Rule-Based",
    "right": "Complex Nuanced",
    "label": "Judging Capability"
  },
  "y_axis": {
    "bottom": "Minimal Data",
    "top": "Extensive Context",
    "label": "Data Requirements"
  }
}
```

Create `configs/llm_eval/examples.csv`:
```csv
x,y,label,group,size
0.1,0.1,"Exact Match","basic",80
0.3,0.2,"Keyword Presence","basic",80
0.5,0.5,"Semantic Similarity","intermediate",120
0.8,0.7,"CoT Judging","advanced",150
0.9,0.9,"Constitutional AI","advanced",150
```

**Step 2: Prompt AI to Generate Variants (5 min)**
```
Based on the base LLM evaluation framework, generate 5 scenario variants:
1. Cost-optimized (emphasizing simple approaches)
2. Accuracy-optimized (emphasizing complex approaches)
3. Startup-friendly (minimal data requirements)
4. Enterprise-scale (extensive data available)
5. Balanced (middle-ground across both dimensions)

For each, generate:
- Modified axes.json with adjusted emphasis
- overlays.json with 2-3 named regions
- examples.csv with 6-8 evaluation approaches

Output as separate directories: scenarios/cost_optimized/, etc.
```

**Step 3: Batch Render (2 min)**
```bash
for scenario in scenarios/*/; do
    python render_quadrant.py "$scenario/config.json"
done
```

**Step 4: Review Ensemble (10 min)**
- Open all 5 PNGs side-by-side
- Identify patterns and outliers
- Select best 2-3 for presentation

**Total time: ~32 minutes to generate and review 5 variants**

---

## Part 10: Integration Checklist

To truly absorb this capability into your workflow:

- [ ] Create personal `/viz_templates` folder with base templates
- [ ] Build `my_viz_style.py` with your preferred aesthetics
- [ ] Generate 10 practice diagrams on different topics (use Week 1-2 exercises)
- [ ] Create first config-based template system
- [ ] Build first data-driven ensemble (5+ variants)
- [ ] Use in 3 real work situations (meetings, memos, decks)
- [ ] Get feedback from colleagues on clarity and impact
- [ ] Refine your atomic prompt library based on what works
- [ ] Document your personal workflow in a README
- [ ] Schedule monthly "diagram review" — what worked, what didn't
- [ ] Share one visualization publicly (LinkedIn/blog) to cement learning

---

## Summary: Three Goals, One Framework

This comprehensive system achieves all three of your objectives:

**1. Produce diagrams quickly:**
- Prompt-only mode: 5-15 minutes from concept to final
- Config-dict mode: 2-5 minutes if template exists
- Data-driven mode: 30 seconds per variant for ensemble exploration

**2. Think more clearly:**
- Conceptual mapping diagnostics force clarity before execution
- Pattern priority guide focuses on highest-leverage visualizations
- CRISP and effectiveness checklists ensure quality thinking

**3. Ship impressive client deliverables:**
- Style consistency through reusable module
- Accessibility and brand safety built in
- Governance/IP hygiene for professional contexts
- Quality bars ensure polished outputs

**The core capability:** You can now rapidly externalize conceptual frameworks into high-quality visual artifacts, iterate through ensembles of scenarios, and integrate visualization thinking into your regular workflow.

---

# Changelog from Previous Version

## Major Additions

1. **Data-Driven Production Modality (NEW)** 
   - **Why:** Enables ensemble analysis and "what-if" scenario exploration beyond single diagrams
   - Added complete JSON schema specifications for axes, overlays, examples
   - Included graceful fallback handling for missing files
   - Provided worked example showing all three production methods
   - Added prompt template for AI-generated scenario variants
   - Created minimal batch renderer script

2. **Pattern Priority Guide (NEW)**
   - **Why:** Focuses learning on highest-impact visualization types first
   - Separated "master deeply" patterns from "use selectively" patterns
   - Aligned with executive/legal/consulting work contexts

3. **Conceptual Mapping Diagnostics (NEW)**
   - **Why:** Bridges gap between "vague idea" and "structural clarity"
   - Added 4-question framework for choosing visualization type
   - Provides decision tree before prompting begins

4. **Atomic Prompt Building Blocks (NEW)**
   - **Why:** Speeds up prompt construction through modular components
   - Organized by function: Structure, Style, Overlays, Gradients, Labels, Export
   - Includes delta iteration template

5. **CRISP Quality Bar (NEW)**
   - **Why:** Provides fast, repeatable pre-export check
   - 5-criterion checklist: Contrast, Readability, Information density, Story, Printability
   - Takes 30 seconds to apply

## Expanded Sections

6. **Skill Progression Path - Enhanced**
   - **Why:** Makes learning concrete with measurable outcomes
   - Added specific time-based metrics (e.g., ≤10 min to first figure by Day 5)
   - Included Week 4 focused on data-driven methods
   - Daily practice structure for each week

7. **Style Module - Complete Implementation**
   - **Why:** Provides copy-paste starting point
   - Full working code for `my_viz_style.py`
   - Vendor-neutral, reusable design
   - Includes export helper with consistent settings

8. **Complete Workflow Examples - Two Full Cases**
   - **Why:** Shows end-to-end application with timing
   - Example 1: Autonomous Entities (prompt-only, 26 minutes)
   - Example 2: LLM Evaluation (data-driven ensemble, 32 minutes)
   - Includes all prompts and file structures

9. **Accessibility & Brand Safety (NEW)**
   - **Why:** Professional deliverables require these standards
   - Colorblind-safe palette requirements
   - 4.5:1 contrast minimum
   - Client brand integration guidance

10. **Governance & IP Hygiene (NEW)**
    - **Why:** Legal/consulting context demands provenance tracking
    - Model version recording
    - Prompt transcript storage
    - License and brand rights considerations

## Structural Improvements

11. **Three Production Modalities Framework**
    - **Why:** Clarifies when to use each approach
    - Organized as: Prompt-only, Config-dict, Data-driven
    - Clear "when to use" guidance for each
    - Progressive complexity path

12. **Error Patterns Table**
    - **Why:** Practical wisdom from common mistakes
    - Organized as: Mistake → Why → Fix
    - Covers 7 most common issues

13. **Integration Checklist**
    - **Why:** Ensures capability becomes part of regular workflow
    - 11 specific action items
    - Progression from setup through sharing

14. **Effectiveness Checklist**
    - **Why:** Ensures diagrams achieve business purpose
    - 5 yes/no criteria (not scored rubric)
    - Fast to apply, clear outcomes

## Removed/Simplified

15. **Removed CLI over-engineering**
    - Original suggestion had complex bash scripting
    - Kept minimal Python runner instead
    - Simpler, more maintainable

16. **Simplified measurement approach**
    - Removed unrealistic "80% stakeholder comprehension" metric
    - Replaced with "get feedback from 3 peers; iterate if 2+ identify confusion"
    - More practical, less pseudo-scientific

---

**Net result:** A comprehensive system that balances conceptual frameworks (how to think about visualization) with practical tools (how to execute quickly) while enabling both single-diagram iteration and ensemble scenario exploration. The data-driven modality specifically addresses your need for second-level analysis and portfolio-scale work.
